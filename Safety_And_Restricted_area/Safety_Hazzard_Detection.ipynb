{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to apply model on video with 4 classes(Vest, NOVest, Helmet, NOHelmet)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_text_and_box_on_image(image, text, position, box_coordinates, font, color):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw bounding box\n",
    "    draw.rectangle(box_coordinates, outline=color, width=2)\n",
    "    \n",
    "    # Draw text with specified color\n",
    "    draw.text(position, text, fill=color, font=font)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_video(video_path, model, output_folder, output_video_path):\n",
    "    # Open the video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the frames per second (fps) of the input video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Create VideoWriter object with the same fps as the input video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    frame_number = 0\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the OpenCV BGR image to RGB (PIL format)\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        try:\n",
    "            results = model.predict(image)\n",
    "            result = results[0]\n",
    "\n",
    "            # Create a font with the desired size\n",
    "            font_size = 20  # Adjust the font size as needed\n",
    "            font = ImageFont.truetype(\"arial.ttf\", font_size)  # Use arial.ttf or another font file with the desired size\n",
    "\n",
    "            # Keep track of whether any detection occurred in this frame\n",
    "            detection_occurred = False\n",
    "\n",
    "            for idx, box in enumerate(result.boxes):\n",
    "                class_id = result.names[box.cls[0].item()]\n",
    "                cords = box.xyxy[0].tolist()\n",
    "                cords = [round(x) for x in cords]\n",
    "                conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "                # Determine color based on class_id\n",
    "                if class_id == \"Helmet\":\n",
    "                    bounding_box_color = (0, 255, 0)  # Green\n",
    "                    text_color = (0, 255, 0)  # Green\n",
    "                elif class_id == \"NOHelmet\":\n",
    "                    bounding_box_color = (0, 0, 255)  # Blue\n",
    "                    text_color = (0, 0, 255)  # Blue\n",
    "                elif class_id == \"NOVest\":\n",
    "                    bounding_box_color = (255, 0, 0)  # Red\n",
    "                    text_color = (255, 0, 0)  # Red\n",
    "                elif class_id == \"Vest\":\n",
    "                    bounding_box_color = (255, 255, 0)  # Yellow\n",
    "                    text_color = (255, 255, 0)  # Yellow\n",
    "                else:\n",
    "                    bounding_box_color = (128, 128, 128)  # Default to gray\n",
    "                    text_color = (128, 128, 128)  # Default to gray\n",
    "\n",
    "                # Draw text and bounding box on the image\n",
    "                text = f\"{class_id}({conf})\"\n",
    "                position = (cords[0], cords[1] - 22)  # Adjust the position based on your preference\n",
    "                image_with_text_and_box = draw_text_and_box_on_image(image, text, position, cords, font, text_color)\n",
    "\n",
    "                # Convert the modified image back to BGR (OpenCV format)\n",
    "                modified_frame = cv2.cvtColor(np.array(image_with_text_and_box), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # If at least one detection occurred, set detection_occurred to True\n",
    "                if not detection_occurred:\n",
    "                    detection_occurred = True\n",
    "\n",
    "            # Write the frame to the output video (outside the detection loop)\n",
    "            out.write(modified_frame) if detection_occurred else out.write(frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_number}: {e}\")\n",
    "\n",
    "        frame_number += 1\n",
    "\n",
    "    # Release the video capture and writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Example usage\n",
    "output_folder = \"Your output folder path\"\n",
    "output_video_path = \"Your output video path\"\n",
    "model = YOLO(\"Your Model path\")\n",
    "video_path = \"Your Input video path\"\n",
    "process_video(video_path, model, output_folder, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
